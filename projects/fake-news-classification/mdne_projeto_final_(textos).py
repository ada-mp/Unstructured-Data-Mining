# -*- coding: utf-8 -*-
"""MDNE - Projeto Final (Textos).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1458ch8sYgbuu3b9tSvt8R47S_gScMWZP

#SCC5920 - Projeto Final (Mineração de Textos)

#Impacto de Representações Textuais em Modelos de Classificação de *Fake News*: Uma Abordagem Comparativa

Ada Maris Pereira Mário - 12725432

##Bibliotecas
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from collections import Counter
from wordcloud import WordCloud
!pip install umap-learn
import umap

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

from sklearn.feature_extraction.text import TfidfVectorizer

import re
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')
nltk.download('punkt')

!pip install gensim
from gensim.models import KeyedVectors
!wget https://zenodo.org/api/files/ce27e83b-fa32-42a7-83bd-60f34ea1e318/GoogleNews-vectors-negative300.bin.gz
w2v = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)

!pip install -U sentence-transformers
from sentence_transformers import SentenceTransformer

from transformers import DistilBertTokenizer, DistilBertModel
import torch

"""## Dados"""

!wget https://zenodo.org/records/4561253/files/WELFake_Dataset.csv

dataset = pd.read_csv('WELFake_Dataset.csv')

dataset

"""### Amostragem, Train/Test Split e Tokenização"""

def sample_dataset(df, n=5000):
  df_clean = df.dropna()

  class_0 = df_clean[df_clean['label'] == 0]
  class_1 = df_clean[df_clean['label'] == 1]

  # Retirar uma amostra balanceada de 5k para cada classe
  sample_class_0 = class_0.sample(n=n, random_state=42)
  sample_class_1 = class_1.sample(n=n, random_state=42)

  balanced_sample = pd.concat([sample_class_0, sample_class_1], axis=0)

  # Embaralhar as amostras para garantir distribuição aleatória
  balanced_sample = balanced_sample.sample(frac=1, random_state=42).reset_index(drop=True)

  return balanced_sample

sampled_dataset = sample_dataset(dataset)
print(sampled_dataset['label'].value_counts())

sampled_dataset['combined'] = sampled_dataset['title'] + sampled_dataset['text']

df_train, df_test = train_test_split(sampled_dataset, test_size=0.33, random_state=42)

df_train

df_test

def preprocess_text(text):
  # Remove caracteres especiais, números, etc.
  text = re.sub(r'\W', ' ', text)
  text = re.sub(r'\s+', ' ', text)
  text = text.lower()  # Colocar tudo em minúsculas
  words = word_tokenize(text)  # Tokenizar o texto
  words = [word for word in words if word not in stopwords.words('english')]  # Remover stopwords
  return words

df_train['processed'] = df_train['combined'].apply(preprocess_text)
df_test['processed'] = df_test['combined'].apply(preprocess_text)

"""## Word2Vec"""

# gerar embeddings médios usando Word2Vec
def avg_w2v(df, model, embedding_dim=300):
  doc_embeddings = []

  for sentence in df['processed']:
    L = [model[token] for token in sentence if token in model]
    if L:  # Se houver palavras com embeddings
      embedding = np.mean(L, axis=0)
    else:  # Caso contrário, vetor de zeros
      embedding = np.zeros(embedding_dim)
    doc_embeddings.append(embedding)

  df['w2v_embeddings'] = doc_embeddings
  return df

df_train = avg_w2v(df_train, w2v, embedding_dim=300)
df_test = avg_w2v(df_test, w2v, embedding_dim=300)

"""##TF-IDF"""

tfidf_train = df_train['processed'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)
tfidf_test = df_test['processed'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)

tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(3,3))

tfidf_train = tfidf_vectorizer.fit_transform(tfidf_train)
tfidf_test = tfidf_vectorizer.transform(tfidf_test)

"""## SBERT"""

model2 = SentenceTransformer('paraphrase-MiniLM-L6-v2')

df_train['bert_embeddings'] = list(model2.encode(df_train.combined.to_list()))
df_test['bert_embeddings'] = list(model2.encode(df_test.combined.to_list()))

"""##DistilBERT"""

tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
model = DistilBertModel.from_pretrained('distilbert-base-uncased')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Usando dispositivo: {device}")
model = model.to(device)

def dbert_embeddings(texts):
  # Tokenizar o texto e mover as entradas para o dispositivo
  inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True).to(device)

  # Desativar gradientes para não computar grad durante a inferência
  with torch.no_grad():
    outputs = model(**inputs)

  # Usamos o embedding do primeiro token [CLS]
  embeddings = outputs.last_hidden_state[:, 0, :]  # Primeira posição corresponde ao token [CLS]

  return embeddings.cpu()

df_train['distilbert_embeddings'] = df_train['combined'].apply(lambda x: dbert_embeddings([x]).squeeze().numpy())
df_test['distilbert_embeddings'] = df_test['combined'].apply(lambda x: dbert_embeddings([x]).squeeze().numpy())

"""## Dataframes finais"""

df_train

df_test

"""##Padronização"""

scaler = StandardScaler().fit(tfidf_train.toarray())
tfidf_train = scaler.transform(tfidf_train.toarray())
tfidf_test = scaler.transform(tfidf_test.toarray())

scaler = StandardScaler().fit(df_train.w2v_embeddings.to_list())
w2v_train = scaler.transform(df_train.w2v_embeddings.to_list())
w2v_test = scaler.transform(df_test.w2v_embeddings.to_list())

scaler = StandardScaler().fit(df_train.bert_embeddings.to_list())
bert_train = scaler.transform(df_train.bert_embeddings.to_list())
bert_test = scaler.transform(df_test.bert_embeddings.to_list())

scaler = StandardScaler().fit(df_train.distilbert_embeddings.to_list())
distilbert_train = scaler.transform(df_train.distilbert_embeddings.to_list())
distilbert_test = scaler.transform(df_test.distilbert_embeddings.to_list())

"""##EDA"""

df_real = df_train[df_train['label'] == 1]
df_fake = df_train[df_train['label'] == 0]

words_real = [word for text in df_real['processed'] for word in text]
word_freq_real = Counter(words_real).most_common(20)

words_fake = [word for text in df_fake['processed'] for word in text]
word_freq_fake = Counter(words_fake).most_common(20)

wreal, counts_real = zip(*word_freq_real)
wfake, counts_fake = zip(*word_freq_fake)

fig, axs = plt.subplots(1, 2, figsize=(10, 5))

sns.barplot(x=counts_real, y=wreal, hue=wreal, palette='Blues_d', ax=axs[0], legend=False)
axs[0].set_title('Top 20 Palavras Frequentes - Notícias Reais', fontweight='bold', fontsize=12)
axs[0].set_xlabel('Frequência')
# axs[0].set_ylabel('Palavras')

sns.barplot(x=counts_fake, y=wfake, hue=wfake, palette='Reds_d', ax=axs[1], legend=False)
axs[1].set_title('Top 20 Palavras Frequentes - Notícias Falsas', fontweight='bold', fontsize=12)
axs[1].set_xlabel('Frequência')
# axs[1].set_ylabel('Palavras')

plt.tight_layout()
plt.show()

fig, axs = plt.subplots(1, 2, figsize=(14, 6))

wordcloud_real = WordCloud(background_color='white').generate(' '.join(words_real))
axs[0].imshow(wordcloud_real, interpolation='bilinear')
axs[0].axis("off")
axs[0].set_title('Nuvem de Palavras - Notícias Reais', fontweight='bold', fontsize=14)

wordcloud_fake = WordCloud(background_color='white').generate(' '.join(words_fake))
axs[1].imshow(wordcloud_fake, interpolation='bilinear')
axs[1].axis("off")
axs[1].set_title('Nuvem de Palavras - Notícias Falsas', fontweight='bold', fontsize=14)

plt.tight_layout()
plt.show()

real_lengths = df_real['processed'].apply(len)
fake_lengths = df_fake['processed'].apply(len)

fig, axs = plt.subplots(1, 2, figsize=(12, 4))

sns.histplot(real_lengths, color='blue', ax=axs[0], kde=True)
axs[0].set_title('Distribuição do Tamanho - Notícias Reais', fontweight='bold', fontsize=12)
axs[0].set_xlabel('Número de Palavras')
axs[0].set_ylabel('Frequência')

sns.histplot(fake_lengths, color='red', ax=axs[1], kde=True)
axs[1].set_title('Distribuição do Tamanho - Notícias Falsas', fontweight='bold', fontsize=12)
axs[1].set_xlabel('Número de Palavras')
axs[1].set_ylabel('Frequência')

plt.tight_layout()
plt.show()

fig, axs = plt.subplots(1, 2, figsize=(12, 4))

sns.histplot(real_lengths, color='blue', ax=axs[0], kde=True)
axs[0].set_title('Distribuição do Tamanho - Notícias Reais (Truncada)', fontweight='bold', fontsize=12)
axs[0].set_xlim([0, 1000])
axs[0].set_xlabel('Número de Palavras (até 1000)')
axs[0].set_ylabel('Frequência')

sns.histplot(fake_lengths, color='red', ax=axs[1], kde=True)
axs[1].set_title('Distribuição do Tamanho - Notícias Falsas (Truncada)', fontweight='bold', fontsize=12)
axs[1].set_xlim([0, 1000])
axs[1].set_xlabel('Número de Palavras (até 1000)')
axs[1].set_ylabel('Frequência')

plt.tight_layout()
plt.show()

def apply_pca(embeddings, n_components=3):
  pca = PCA(n_components=n_components)
  reduced_embeddings = pca.fit_transform(embeddings)
  return reduced_embeddings, pca

tfidf_pca, tfidf_pca_model = apply_pca(tfidf_train)

w2v_pca, w2v_pca_model = apply_pca(w2v_train)

bert_pca, bert_pca_model = apply_pca(bert_train)

distilbert_pca, distilbert_pca_model = apply_pca(distilbert_train)

fig = plt.figure(figsize=(32, 48))

ax1 = fig.add_subplot(141, projection='3d')
ax1.scatter(tfidf_pca[:, 0], tfidf_pca[:, 1], tfidf_pca[:, 2], c=df_train['label'], cmap='tab10')
ax1.set_title("PCA 3D - TF-IDF")
ax1.set_xlabel('PC1')
ax1.set_ylabel('PC2')
ax1.set_zlabel('PC3')

ax2 = fig.add_subplot(142, projection='3d')
ax2.scatter(w2v_pca[:, 0], w2v_pca[:, 1], w2v_pca[:, 2], c=df_train['label'], cmap='tab10')
ax2.set_title("PCA 3D - Word2Vec")
ax2.set_xlabel('PC1')
ax2.set_ylabel('PC2')
ax2.set_zlabel('PC3')

ax3 = fig.add_subplot(143, projection='3d')
ax3.scatter(bert_pca[:, 0], bert_pca[:, 1], bert_pca[:, 2], c=df_train['label'], cmap='tab10')
ax3.set_title("PCA 3D - SBERT")
ax3.set_xlabel('PC1')
ax3.set_ylabel('PC2')
ax3.set_zlabel('PC3')

ax4 = fig.add_subplot(144, projection='3d')
ax4.scatter(distilbert_pca[:, 0], distilbert_pca[:, 1], distilbert_pca[:, 2], c=df_train['label'], cmap='tab10')
ax4.set_title("PCA 3D - DistilBERT")
ax4.set_xlabel('PC1')
ax4.set_ylabel('PC2')
ax4.set_zlabel('PC3')

plt.tight_layout()
plt.show()

def umap_projection(X, y, title, n_neighbors=16, min_dist=0.1, n_components=2):
  umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=42)
  X_umap = umap_model.fit_transform(X, y)
  return X_umap

y = df_train['label']
X_tfidf_umap = umap_projection(tfidf_train, y, "TF-IDF")
X_w2v_umap = umap_projection(w2v_train, y, "Word2Vec")
X_sbert_umap = umap_projection(bert_train, y, "SBERT")
X_distilbert_umap = umap_projection(distilbert_train, y, "DistilBERT")

fig, axes = plt.subplots(1, 4, figsize=(18, 5))

sns.scatterplot(x=X_tfidf_umap[:, 0], y=X_tfidf_umap[:, 1], hue=y, palette='coolwarm', s=60, ax=axes[0])
axes[0].set_title("TF-IDF UMAP Projection", fontweight="bold")

sns.scatterplot(x=X_w2v_umap[:, 0], y=X_w2v_umap[:, 1], hue=y, palette='coolwarm', s=60, ax=axes[1])
axes[1].set_title("Word2Vec UMAP Projection", fontweight="bold")

sns.scatterplot(x=X_sbert_umap[:, 0], y=X_sbert_umap[:, 1], hue=y, palette='coolwarm', s=60, ax=axes[2])
axes[2].set_title("SBERT UMAP Projection", fontweight="bold")

sns.scatterplot(x=X_distilbert_umap[:, 0], y=X_distilbert_umap[:, 1], hue=y, palette='coolwarm', s=60, ax=axes[3])
axes[3].set_title("DistilBERT UMAP Projection", fontweight="bold")

plt.tight_layout()
plt.show()

"""## KNN

###TF-IDF
"""

# identificação dos melhores parâmetros para o knn neste problema
knn = KNeighborsClassifier()
param_grid = [{'n_neighbors': np.arange(1, 21),
               'metric': ['euclidean', 'minkowski','manhattan', 'cosine']}]

model = GridSearchCV(knn, param_grid)

model.fit(tfidf_train, df_train['label'])
print(model.best_params_)
model.score(tfidf_train, df_train['label'])

knn = KNeighborsClassifier(n_neighbors=17,metric="cosine", weights='distance')
knn.fit(tfidf_train, df_train['label'])
y_pred = knn.predict(tfidf_test)
y_pred

print(classification_report(df_test['label'], y_pred))

scores = cross_val_score(knn, tfidf_test, df_test['label'])
print(scores)
print(scores.mean())

cm = confusion_matrix(df_test['label'], y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

y_score = knn.predict_proba(tfidf_test)[:, 1]

fpr, tpr, thresholds = roc_curve(df_test['label'], y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(4, 3))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

#dados que serão utilizados para wilcoxon
tfidf_scores = [
    round(accuracy_score(df_test['label'], y_pred), 4),
    round(precision_score(df_test['label'], y_pred), 4),
    round(recall_score(df_test['label'], y_pred), 4),
    round(f1_score(df_test['label'], y_pred), 4),
    round(roc_auc_score(df_test['label'], knn.predict_proba(tfidf_test)[:, 1]), 4)
]

"""###W2V"""

# identificação dos melhores parâmetros para o knn neste problema
knn = KNeighborsClassifier()
param_grid = [{'n_neighbors': np.arange(1, 21),
               'weights': ['uniform', 'distance'],
               'metric': ['euclidean', 'minkowski','manhattan','chebyshev', 'cosine']}]

model = GridSearchCV(knn, param_grid)

model.fit(w2v_train, df_train['label'])
print(model.best_params_)
model.score(w2v_train, df_train['label'])

knn = KNeighborsClassifier(n_neighbors=19,metric="cosine", weights='distance')
knn.fit(w2v_train, df_train['label'])
y_pred = knn.predict(w2v_test)
y_pred

print(classification_report(df_test['label'], y_pred))

scores = cross_val_score(knn, w2v_test, df_test['label'])
print(scores)
print(scores.mean())

cm = confusion_matrix(df_test['label'], y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

y_score = knn.predict_proba(w2v_test)[:, 1]

fpr, tpr, thresholds = roc_curve(df_test['label'], y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(4, 3))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

#dados que serão utilizados para wilcoxon
w2v_scores = [
    round(accuracy_score(df_test['label'], y_pred), 4),
    round(precision_score(df_test['label'], y_pred), 4),
    round(recall_score(df_test['label'], y_pred), 4),
    round(f1_score(df_test['label'], y_pred), 4),
    round(roc_auc_score(df_test['label'], knn.predict_proba(w2v_test)[:, 1]), 4)
]

"""###SBert"""

# identificação dos melhores parâmetros para o knn neste problema
knn = KNeighborsClassifier()
param_grid = [{'n_neighbors': np.arange(1, 21),
               'weights': ['uniform', 'distance'],
               'metric': ['euclidean', 'minkowski','manhattan','chebyshev', 'cosine']}]

model = GridSearchCV(knn, param_grid)

model.fit(bert_train, df_train['label'])
print(model.best_params_)
model.score(bert_train, df_train['label'])

knn = KNeighborsClassifier(n_neighbors=18,metric="cosine", weights='distance')
knn.fit(bert_train, df_train['label'])
y_pred = knn.predict(bert_test)
y_pred

print(classification_report(df_test['label'], y_pred))

scores = cross_val_score(knn, bert_test, df_test['label'])
print(scores)
print(scores.mean())

cm = confusion_matrix(df_test['label'], y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

y_score = knn.predict_proba(bert_test)[:, 1]

fpr, tpr, thresholds = roc_curve(df_test['label'], y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(4, 3))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

#dados que serão utilizados para wilcoxon
sbert_scores = [
    round(accuracy_score(df_test['label'], y_pred), 4),
    round(precision_score(df_test['label'], y_pred), 4),
    round(recall_score(df_test['label'], y_pred), 4),
    round(f1_score(df_test['label'], y_pred), 4),
    round(roc_auc_score(df_test['label'], knn.predict_proba(bert_test)[:, 1]), 4)
]

"""###DistilBERT"""

# identificação dos melhores parâmetros para o knn neste problema
knn = KNeighborsClassifier()
param_grid = [{'n_neighbors': np.arange(1, 21),
               'weights': ['uniform', 'distance'],
               'metric': ['euclidean', 'minkowski','manhattan','chebyshev', 'cosine']}]

model = GridSearchCV(knn, param_grid)

model.fit(distilbert_train, df_train['label'])
print(model.best_params_)
model.score(distilbert_train, df_train['label'])

knn = KNeighborsClassifier(n_neighbors=10,metric="manhattan", weights='distance')
knn.fit(distilbert_train, df_train['label'])
y_pred = knn.predict(distilbert_test)
y_pred

print(classification_report(df_test['label'], y_pred))

scores = cross_val_score(knn, distilbert_test, df_test['label'])
print(scores)
print(scores.mean())

cm = confusion_matrix(df_test['label'], y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

y_score = knn.predict_proba(distilbert_test)[:, 1]

fpr, tpr, thresholds = roc_curve(df_test['label'], y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(4, 3))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

#dados que serão utilizados para wilcoxon
distilbert_scores = [
    round(accuracy_score(df_test['label'], y_pred), 4),
    round(precision_score(df_test['label'], y_pred), 4),
    round(recall_score(df_test['label'], y_pred), 4),
    round(f1_score(df_test['label'], y_pred), 4),
    round(roc_auc_score(df_test['label'], knn.predict_proba(distilbert_test)[:, 1]), 4)
]

"""##Teste de Wilcoxon para dados pareados"""

print("tfidf_scores:", tfidf_scores)
print("w2v_scores:", w2v_scores)
print("sbert_scores:", sbert_scores)
print("distilbert_scores:", distilbert_scores)

# considerando a ordem dos termos nas linhas dos prints, temos que o modelo da direita ("grupo tratamento")
# é o que está sendo testado ter desempenho maior (>) que o da esquerda ("grupo controle")
from scipy.stats import wilcoxon
print('tfidf x w2v:', wilcoxon(w2v_scores, tfidf_scores, alternative='greater'))
print('tfidf x sbert:', wilcoxon(sbert_scores, tfidf_scores, alternative='greater'))
print('tfidf x distilbert:', wilcoxon(distilbert_scores, tfidf_scores, alternative='greater'))
print('w2v x sbert:', wilcoxon(sbert_scores, w2v_scores, alternative='greater'))
print('w2v x distilbert:', wilcoxon(distilbert_scores, w2v_scores, alternative='greater'))
print('sbert x distilbert:', wilcoxon(distilbert_scores, sbert_scores, alternative='greater'))

# testes bônus mas não inclusos no relatório
print('tfidf x w2v:', wilcoxon(w2v_scores, tfidf_scores, alternative='less'))
print('tfidf x sbert:', wilcoxon(sbert_scores, tfidf_scores, alternative='less'))
print('tfidf x distilbert:', wilcoxon(distilbert_scores, tfidf_scores, alternative='less'))
print('w2v x sbert:', wilcoxon(sbert_scores, w2v_scores, alternative='less'))
print('w2v x distilbert:', wilcoxon(distilbert_scores, w2v_scores, alternative='less'))
print('sbert x distilbert:', wilcoxon(distilbert_scores, sbert_scores, alternative='less'))