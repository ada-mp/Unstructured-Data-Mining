# -*- coding: utf-8 -*-
"""MDNE - Projeto Final (Imagens).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LthCF6cKpQYf0GKx3yCuE0Ao2NCmA12P

#SCC5920 - Projeto Final (Mineração de Imagens)

#Análise Comparativa de Representações de Imagens em Classificação de Figuras Sintéticas

Ada Maris Pereira Mário - 12725432

##Bibliotecas
"""

import pandas as pd
import numpy as np
import os
from PIL import Image
import cv2
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
import seaborn as sns
import random

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score


!pip install mahotas
import mahotas as mt

import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from torch.autograd import Variable

"""## Dados"""

# Para carregar os dados diretamente do kaggle precisa do arquivo json da sua conta
# Do contrário, fazer o processo manual usual a partir de:
# https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images

# Carregar o arquivo kaggle.json para o Google Colab
from google.colab import files
files.upload()  # Selecione o arquivo kaggle.json que foi baixado

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d birdy654/cifake-real-and-ai-generated-synthetic-images

# Descompactar o arquivo baixado
!unzip cifake-real-and-ai-generated-synthetic-images.zip

def load_images_labels(directory):
  image_files = []
  labels = []
  for label in ['REAL', 'FAKE']:
    for img_file in os.listdir(os.path.join(directory, label)):
      if img_file.endswith('.jpg') or img_file.endswith('.png'):
        image_files.append(os.path.join(directory, label, img_file))
        labels.append(0 if label == 'REAL' else 1)
  return pd.DataFrame({'image_path': image_files, 'label': labels})

img_train = load_images_labels("/content/train/")
img_test = load_images_labels("/content/test/")

img_train

img_test

"""##Histograma de Cor"""

def color_histogram(image, bins=(8, 8, 8)):
  image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
  hist = cv2.calcHist([image], [0, 1, 2], None, bins, [0, 256, 0, 256, 0, 256])
  hist = cv2.normalize(hist, hist).flatten()  # Normaliza e achata o histograma em um vetor
  return hist

img_train['color_hist'] = img_train['image_path'].apply(lambda x: color_histogram(Image.open(x)))
img_test['color_hist'] = img_test['image_path'].apply(lambda x: color_histogram(Image.open(x)))

"""##Textura"""

def haralick_features(image_path):
  try:
    img = Image.open(image_path).convert('L')  # Converte para tons de cinza
    img = np.array(img)

    haralick_textures = mt.features.haralick(img)
    haralick_mean = haralick_textures.mean(axis=0)

    return haralick_mean
  except Exception as e:
    print(f"Erro ao processar {image_path}: {e}")
    return None

img_train['haralick_features'] = img_train['image_path'].apply(haralick_features)
img_test['haralick_features'] = img_test['image_path'].apply(haralick_features)

"""##Resnet"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Usando dispositivo: {device}")

model = models.resnet18(pretrained=True)
model = model.to(device)
model.eval()  # Coloca o modelo em modo de avaliação para desativar camadas de dropout

# Captura a saída da penúltima camada (antes da camada de classificação final)
layer = model._modules.get('avgpool')

scaler = transforms.Resize((224, 224))
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
to_tensor = transforms.ToTensor()

def resnet_embeddings(image_path):
  img = Image.open(image_path).convert('RGB')
  img_transformada = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)).to(device)

  embedding = torch.zeros(512).to(device)

  def capturar_embedding(m, i, o):
    embedding.copy_(o.data.reshape(o.data.size(1)))

  h = layer.register_forward_hook(capturar_embedding)
  model(img_transformada)
  h.remove()

  return embedding.cpu().numpy()

img_train['resnet_embedding'] = img_train['image_path'].apply(lambda x: resnet_embeddings(x))
img_test['resnet_embedding'] = img_test['image_path'].apply(lambda x: resnet_embeddings(x))

"""##Dataframes finais"""

img_train

img_test

"""##Padronização"""

scaler = StandardScaler().fit(img_train.color_hist.to_list())
color_train = scaler.transform(img_train.color_hist.to_list())
color_test = scaler.transform(img_test.color_hist.to_list())

scaler = StandardScaler().fit(img_train.haralick_features.to_list())
haralick_train = scaler.transform(img_train.haralick_features.to_list())
haralick_test = scaler.transform(img_test.haralick_features.to_list())

scaler = StandardScaler().fit(img_train.resnet_embedding.to_list())
resnet_train = scaler.transform(img_train.resnet_embedding.to_list())
resnet_test = scaler.transform(img_test.resnet_embedding.to_list())

"""##EDA"""

fig, axs = plt.subplots(1, 2, figsize=(9,4))

sns.countplot(x='label', data=img_train, ax=axs[0])
axs[0].set_title('Distribuição de Classes no Conjunto de Treino')
axs[0].set_xlabel('Classe')
axs[0].set_ylabel('Número de Imagens')

sns.countplot(x='label', data=img_test, ax=axs[1])
axs[1].set_title('Distribuição de Classes no Conjunto de Teste')
axs[1].set_xlabel('Classe')
axs[1].set_ylabel('Número de Imagens')

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(1, 5, figsize=(8,4))
real_images = img_train[img_train['label'] == 0]['image_path'].sample(5).values
for i, img_path in enumerate(real_images):
  img = Image.open(img_path)
  axes[i].imshow(img)
  axes[i].axis('off')
  axes[i].set_title('Real')

plt.show()

fig, axes = plt.subplots(1, 5, figsize=(8,4))
fake_images = img_train[img_train['label'] == 1]['image_path'].sample(5).values
for i, img_path in enumerate(fake_images):
  img = Image.open(img_path)
  axes[i].imshow(img)
  axes[i].axis('off')
  axes[i].set_title('Gerada por IA')

plt.show()

def colorhist(image, ax, label):
  chans = cv2.split(image)
  colors = ('b', 'g', 'r')
  for (chan, color) in zip(chans, colors):
    # Calcular o histograma para cada canal
    hist = cv2.calcHist([chan], [0], None, [256], [0, 256])
    ax.plot(hist, color=color)
    ax.set_xlim([0, 256])
    ax.set_title(f"Histograma de Cores - {label}")
    ax.set_xlabel('Intensidade')
    ax.set_ylabel('Frequência')


fig, axs = plt.subplots(1, 2, figsize=(10, 5))

real_path = img_train[img_train['label'] == 0]['image_path'].values[0]
real_image = cv2.imread(real_path)
colorhist(real_image, axs[0], 'Exemplo Imagem Real')

fake_path = img_train[img_train['label'] == 1]['image_path'].values[0]
fake_image = cv2.imread(fake_path)
colorhist(fake_image, axs[1], 'Exemplo Imagem Fake')

plt.tight_layout()
plt.show()

from sklearn.decomposition import PCA
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(9, 6))

resnet_embeddings_train = np.stack(img_train['resnet_embedding'].values)
pca_train = PCA(n_components=3).fit_transform(resnet_embeddings_train)
df_pca_train = pd.DataFrame({'pca_1': pca_train[:, 0], 'pca_2': pca_train[:, 1], 'pca_3': pca_train[:, 2], 'label': img_train['label']})

ax = fig.add_subplot(121, projection='3d')
sc = ax.scatter(df_pca_train['pca_1'], df_pca_train['pca_2'], df_pca_train['pca_3'], c=df_pca_train['label'], cmap='viridis')
ax.set_title('Embeddings ResNet - PCA 3D (Treino)')
ax.set_xlabel('PCA 1')
ax.set_ylabel('PCA 2')
ax.set_zlabel('PCA 3')
fig.colorbar(sc)

resnet_embeddings_test = np.stack(img_test['resnet_embedding'].values)
pca_test = PCA(n_components=3).fit_transform(resnet_embeddings_test)
df_pca_test = pd.DataFrame({'pca_1': pca_test[:, 0], 'pca_2': pca_test[:, 1], 'pca_3': pca_test[:, 2], 'label': img_test['label']})

ax = fig.add_subplot(122, projection='3d')
sc = ax.scatter(df_pca_test['pca_1'], df_pca_test['pca_2'], df_pca_test['pca_3'], c=df_pca_test['label'], cmap='viridis')
ax.set_title('Embeddings ResNet - PCA 3D (Teste)')
ax.set_xlabel('PCA 1')
ax.set_ylabel('PCA 2')
ax.set_zlabel('PCA 3')
fig.colorbar(sc)

plt.tight_layout()
plt.show()

"""##KNN

###Cores
"""

knn = KNeighborsClassifier()
param_grid = [{'n_neighbors': np.arange(1, 21),
               'metric': ['euclidean','manhattan', 'cosine']}]

model = RandomizedSearchCV(knn, param_grid)

model.fit(color_train, img_train['label'])
print(model.best_params_)
model.score(color_train, img_train['label'])

"""Saída encontrada ao rodar o código acima no VS Code em outra máquina (Não consegui rodar no Colab): \
`{'n_neighbors': np.int64(8), 'metric': 'manhattan'}`
"""

knn = KNeighborsClassifier(n_neighbors=8,metric="manhattan", weights='distance')
knn.fit(color_train, img_train['label'])
y_pred = knn.predict(color_test)
print(classification_report(img_test['label'], y_pred))

scores = cross_val_score(knn, color_test, img_test['label'])
print(scores)
print(scores.mean())

cm = confusion_matrix(img_test['label'], y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

y_score = knn.predict_proba(color_test)[:, 1]

fpr, tpr, thresholds = roc_curve(img_test['label'], y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(4, 3))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

#dados que serão utilizados para wilcoxon
color_scores = [
    round(accuracy_score(img_test['label'], y_pred), 4),
    round(precision_score(img_test['label'], y_pred), 4),
    round(recall_score(img_test['label'], y_pred), 4),
    round(f1_score(img_test['label'], y_pred), 4),
    round(roc_auc_score(img_test['label'], knn.predict_proba(color_test)[:, 1]), 4)
]

"""###Textura"""

knn = KNeighborsClassifier()
param_grid = [{'n_neighbors': np.arange(1, 21),
               'metric': ['euclidean', 'minkowski','manhattan','chebyshev', 'cosine']}]

model = GridSearchCV(knn, param_grid)

model.fit(haralick_train, img_train['label'])
print(model.best_params_)
model.score(haralick_train, img_train['label'])

knn = KNeighborsClassifier(n_neighbors=20,metric="manhattan", weights='distance')
knn.fit(haralick_train, img_train['label'])
y_pred = knn.predict(haralick_test)
print(classification_report(img_test['label'], y_pred))

scores = cross_val_score(knn, haralick_test, img_test['label'])
print(scores)
print(scores.mean())

cm = confusion_matrix(img_test['label'], y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

y_score = knn.predict_proba(haralick_test)[:, 1]

fpr, tpr, thresholds = roc_curve(img_test['label'], y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(4, 3))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

#dados que serão utilizados para wilcoxon
haralick_scores = [
    round(accuracy_score(img_test['label'], y_pred), 4),
    round(precision_score(img_test['label'], y_pred), 4),
    round(recall_score(img_test['label'], y_pred), 4),
    round(f1_score(img_test['label'], y_pred), 4),
    round(roc_auc_score(img_test['label'], knn.predict_proba(haralick_test)[:, 1]), 4)
]

"""###Resnet"""

knn = KNeighborsClassifier()
param_grid = [{'n_neighbors': np.arange(1, 21),
               'metric': ['euclidean','manhattan', 'cosine']}]

model = RandomizedSearchCV(knn, param_grid)

model.fit(resnet_train, img_train['label'])
print(model.best_params_)
model.score(resnet_train, img_train['label'])

"""Saída encontrada ao rodar o código acima no VS Code em outra máquina (Não consegui rodar no Colab): \
`{'n_neighbors': np.int64(13), 'metric': 'euclidean'}` \
`0.9115`
"""

knn = KNeighborsClassifier(n_neighbors=13, metric="euclidean", weights='distance')
knn.fit(resnet_train, img_train['label'])
y_pred = knn.predict(resnet_test)
print(classification_report(img_test['label'], y_pred))

scores = cross_val_score(knn, resnet_test, img_test['label'])
print(scores)
print(scores.mean())

cm = confusion_matrix(img_test['label'], y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

y_score = knn.predict_proba(resnet_test)[:, 1]

fpr, tpr, thresholds = roc_curve(img_test['label'], y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(4, 3))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

#dados que serão utilizados para wilcoxon
resnet_scores = [
    round(accuracy_score(img_test['label'], y_pred), 4),
    round(precision_score(img_test['label'], y_pred), 4),
    round(recall_score(img_test['label'], y_pred), 4),
    round(f1_score(img_test['label'], y_pred), 4),
    round(roc_auc_score(img_test['label'], knn.predict_proba(resnet_test)[:, 1]), 4)
]

"""##Teste de Wilcoxon para dados pareados"""

print("color_scores:", color_scores)
print("haralick_scores:", haralick_scores)
print("resnet_scores:", resnet_scores)

from scipy.stats import wilcoxon
print('color x haralick:', wilcoxon(haralick_scores, color_scores, alternative='greater'))
print('color x resnet:', wilcoxon(resnet_scores, color_scores, alternative='greater'))
print('haralick x resnet:', wilcoxon(resnet_scores, haralick_scores, alternative='greater'))

